{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a4e01921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis routine detects heatwave events across the entire spatial grid using the 95th percentile threshold, generating a dataset with event flags, magnitudes, and anomalies.\\n\\nDaniela Risaro\\nJuly 2025\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "This routine detects heatwave events across the entire spatial grid using the 95th percentile threshold, generating a dataset with event flags, magnitudes, and anomalies.\n",
    "\n",
    "Daniela Risaro\n",
    "July 2025\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7ba78c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1786a8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_events(arr_bool, amount_days=5):\n",
    "    result = np.zeros_like(arr_bool, dtype=np.int8)\n",
    "    count = 0\n",
    "    for i in range(len(arr_bool)):\n",
    "        if arr_bool[i]:\n",
    "            count += 1\n",
    "        else:\n",
    "            if count >= amount_days:\n",
    "                result[i - count:i] = 1\n",
    "            count = 0\n",
    "    if count >= amount_days:\n",
    "        result[len(arr_bool) - count:] = 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7cbb42af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_processed_dir = \"../data/processed/\"\n",
    "data_raw_dir = \"../data/raw/\"\n",
    "\n",
    "region = [6, -74, -34, -33]\n",
    "\n",
    "climatology_years = [2005, 2024]\n",
    "file_percentiles = f'tmax2m_mean_and_percentiles_{climatology_years[0]}_{climatology_years[1]}_area_{region[0]}N_{region[1]}W_{region[2]}S_{region[3]}E.nc'\n",
    "files_raw = sorted([file for file in os.listdir(data_raw_dir) if file.endswith(\".nc\")])\n",
    "\n",
    "ds_percentiles = xr.open_dataset(data_processed_dir + file_percentiles)\n",
    "\n",
    "# --- Recorte espacial S찾o Paulo ---\n",
    "lat_min, lat_max = -25.4, -19.7\n",
    "lon_min, lon_max = -53.25, -44\n",
    "\n",
    "if ds_percentiles.latitude[0] > ds_percentiles.latitude[-1]:\n",
    "    ds_percentiles = ds_percentiles.sel(latitude=slice(lat_max, lat_min), longitude=slice(lon_min, lon_max))\n",
    "else:\n",
    "    ds_percentiles = ds_percentiles.sel(latitude=slice(lat_min, lat_max), longitude=slice(lon_min, lon_max))\n",
    "# ----------------------------------\n",
    "\n",
    "percentile = 98 \n",
    "p_percentile = ds_percentiles[f't2m_p{percentile}']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b92c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing year 2010\n",
      "Processing year 2011\n",
      "Processing year 2012\n",
      "Processing year 2013\n",
      "Processing year 2014\n",
      "Processing year 2015\n",
      "Processing year 2016\n",
      "Processing year 2017\n",
      "Processing year 2018\n",
      "Processing year 2019\n",
      "Processing year 2020\n",
      "Processing year 2021\n",
      "Processing year 2022\n",
      "Processing year 2023\n",
      "Processing year 2024\n",
      "Processing year 2025\n"
     ]
    }
   ],
   "source": [
    "\n",
    "list_datasets = []\n",
    "\n",
    "list_years = np.arange(2010, 2026)\n",
    "\n",
    "amount_days = [3, 5, 7]\n",
    "\n",
    "for iamount in amount_days:\n",
    "        \n",
    "    for year in list_years:\n",
    "        print(f\"Processing year {year}\")\n",
    "        variable = \"tmax\"\n",
    "        region = [6, -74, -34, -33]  # misma regi처n de tus archivos\n",
    "        file_year = [\n",
    "            f for f in files_raw\n",
    "            if variable in f and all(str(abs(coord)) in f for coord in region) and f\"_{year}_\" in f\n",
    "        ]\n",
    "        if not file_year:\n",
    "            print(f\"No se encontr처 archivo para {year}\")\n",
    "            continue\n",
    "\n",
    "        ds_year = xr.open_dataset(os.path.join(data_raw_dir, file_year[0]))\n",
    "\n",
    "        # --- Recorte espacial S찾o Paulo ---\n",
    "        if ds_year.latitude[0] > ds_year.latitude[-1]:\n",
    "            ds_year = ds_year.sel(latitude=slice(lat_max, lat_min), longitude=slice(lon_min, lon_max))\n",
    "        else:\n",
    "            ds_year = ds_year.sel(latitude=slice(lat_min, lat_max), longitude=slice(lon_min, lon_max))\n",
    "        # ----------------------------------\n",
    "\n",
    "        ds_year = ds_year[\"t2m\"] - 273.15\n",
    "        ds_year['doy'] = ds_year[\"valid_time\"].dt.dayofyear\n",
    "\n",
    "        time_len = ds_year.sizes[\"valid_time\"]\n",
    "        lat_len = len(ds_percentiles.latitude)\n",
    "        lon_len = len(ds_percentiles.longitude)\n",
    "\n",
    "        dummy_all = np.zeros((time_len, lat_len, lon_len), dtype=np.int8)\n",
    "        magnitude_all = np.full((time_len, lat_len, lon_len), np.nan, dtype=np.float32)\n",
    "        anomaly_all = np.full((time_len, lat_len, lon_len), np.nan, dtype=np.float32)\n",
    "\n",
    "        for lat_idx in range(lat_len):\n",
    "            for lon_idx in range(lon_len):\n",
    "                target_year_point = ds_year.isel(latitude=lat_idx, longitude=lon_idx)\n",
    "                p_percentile_point = p_percentile.isel(latitude=lat_idx, longitude=lon_idx)\n",
    "                threshold = p_percentile_point.sel(doy=target_year_point['doy'])\n",
    "\n",
    "                excess = target_year_point - threshold\n",
    "                exceeds = excess > 0\n",
    "\n",
    "                dummy = detect_events(exceeds.values, amount_days=iamount)\n",
    "                dummy_all[:, lat_idx, lon_idx] = dummy\n",
    "                magnitude_all[:, lat_idx, lon_idx] = target_year_point.where(dummy == 1).values\n",
    "                anomaly_all[:, lat_idx, lon_idx] = excess.where(dummy == 1).values\n",
    "\n",
    "        ds_out = xr.Dataset(\n",
    "            {\n",
    "                \"tmax2m\": ([\"valid_time\", \"latitude\", \"longitude\"], ds_year.values),\n",
    "                \"event_dummy\": ([\"valid_time\", \"latitude\", \"longitude\"], dummy_all),\n",
    "                \"magnitude_event\": ([\"valid_time\", \"latitude\", \"longitude\"], magnitude_all),\n",
    "                \"anomaly_event\": ([\"valid_time\", \"latitude\", \"longitude\"], anomaly_all),\n",
    "            },\n",
    "            coords={\n",
    "                \"valid_time\": ds_year[\"valid_time\"].values,\n",
    "                \"latitude\": ds_year[\"latitude\"].values,\n",
    "                \"longitude\": ds_year[\"longitude\"].values\n",
    "            }\n",
    "        )\n",
    "\n",
    "        ds_out = ds_out.expand_dims(year=[year])\n",
    "        list_datasets.append(ds_out)\n",
    "\n",
    "    final_ds = xr.concat(list_datasets, dim=\"year\")\n",
    "\n",
    "    output_path = os.path.join(data_processed_dir, f\"heatwaves_{list_years[0]}_{list_years[-1]}_p{percentile}_events_{iamount}_days_area_sao_paulo.nc\")\n",
    "    final_ds.to_netcdf(output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1300699a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heatwaves_2010_2025_p98_events_7_days_area_sao_paulo.nc\n"
     ]
    }
   ],
   "source": [
    "print(f\"heatwaves_{list_years[0]}_{list_years[-1]}_p{percentile}_events_{amount_days}_days_area_sao_paulo.nc\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climate-gdal-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
